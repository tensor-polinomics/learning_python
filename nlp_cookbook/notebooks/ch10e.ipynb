{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04495b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest Nobel Prize in Economics for 2023 was awarded to Claudia Goldin for her work in advancing the understanding of women's labor market outcomes. She is notable for being the third woman to receive this prestigious award.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Bind tool to LLM\n",
    "llm_with_tools = llm.bind_tools([search])\n",
    "\n",
    "def run_agent(query: str) -> str:\n",
    "    messages = [HumanMessage(content=query)]\n",
    "    \n",
    "    # First LLM call\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    messages.append(response)\n",
    "    \n",
    "    # Check if tool call needed\n",
    "    if response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            result = search.invoke(tool_call[\"args\"][\"query\"])\n",
    "            messages.append(ToolMessage(content=result, tool_call_id=tool_call[\"id\"]))\n",
    "        \n",
    "        # Final LLM call with tool results\n",
    "        response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Run\n",
    "answer = run_agent(\"Who won the latest Nobel Prize in Economics?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9e1764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using: duckduckgo_search({'query': 'current population of Tokyo 2023'})\n",
      "ðŸ“„ Result: 6 hours ago - Tokyo, officially the Tokyo Metropolis, is the capital and most populous city in Japan. With a population of over 14 million in the city proper in 2023, it is one of the most populous ur\n",
      "ðŸ”§ Using: calculate({'expression': '14000000 * 2'})\n",
      "ðŸ“„ Result: 28000000\n",
      "\n",
      "âœ… The population of Tokyo is over 14 million. When multiplied by 2, the result is 28 million.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a math expression. Example: '2 + 2' or '15 * 7'.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "tools = [search, calculate]\n",
    "tool_map = {t.name: t for t in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def run_agent(query: str, verbose: bool = True) -> str:\n",
    "    messages = [HumanMessage(content=query)]\n",
    "    \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    messages.append(response)\n",
    "    \n",
    "    while response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            if verbose:\n",
    "                print(f\"ðŸ”§ Using: {tool_call['name']}({tool_call['args']})\")\n",
    "            result = tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            if verbose:\n",
    "                print(f\"ðŸ“„ Result: {str(result)[:200]}\")\n",
    "            messages.append(ToolMessage(content=str(result), tool_call_id=tool_call[\"id\"]))\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        messages.append(response)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Test: requires both search and calculation\n",
    "answer = run_agent(\"What is the population of Tokyo? Multiply that number by 2.\")\n",
    "print(f\"\\nâœ… {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7236717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
