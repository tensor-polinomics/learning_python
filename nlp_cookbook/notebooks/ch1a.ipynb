{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../util\")\n",
    "from file_utils import read_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5934f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlock_holmes_part_of_text = read_text_file(\"../data/sherlock_holmes_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b3e378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
      "mention her under any other name. In his eyes she eclipses and\n",
      "predominates the whole of her sex. It was not that he felt any emotion\n",
      "akin to love for Irene Adler. All emotions, and that one particularly,\n",
      "were abhorrent to his cold, precise but admirably balanced mind. He\n",
      "was, I take it, the most perfect reasoning and observing machine that\n",
      "the world has seen, but as a lover he would have placed himself in a\n",
      "false position. He\n"
     ]
    }
   ],
   "source": [
    "print(sherlock_holmes_part_of_text[:500])  # Print the first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae386cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break text into sentences using NLTK's pre-trained Punkt tokenizer\n",
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "sentences_nltk = tokenizer.tokenize(sherlock_holmes_part_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7abd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To Sherlock Holmes she is always _the_ woman.', 'I have seldom heard him\\nmention her under any other name.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(sentences_nltk[:2])\n",
    "print(len(sentences_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58a789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To Sherlock Holmes she is always _the_ woman.', 'I have seldom heard him\\nmention her under any other name.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Sentence splitting using spaCy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sherlock_holmes_part_of_text)\n",
    "sentences_spacy = [sent.text for sent in doc.sents]\n",
    "print(sentences_spacy[:2])\n",
    "print(len(sentences_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e4ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK sentence splitting took 0.0005 seconds.\n",
      "spaCy sentence splitting took 0.0898 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def split_into_sentences_nltk(text):\n",
    "    sentences = tokenizer.tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "nltk_sentences = split_into_sentences_nltk(sherlock_holmes_part_of_text)\n",
    "end = time.time()\n",
    "print(f\"NLTK sentence splitting took {end - start:.4f} seconds.\")\n",
    "\n",
    "start = time.time()\n",
    "spacy_sentences = split_into_sentences_spacy(sherlock_holmes_part_of_text)\n",
    "end = time.time()\n",
    "print(f\"spaCy sentence splitting took {end - start:.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad361252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_the_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name']\n",
      "Number of words based on NLTK: 230\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization using NLTK\n",
    "words_nltk = nltk.tokenize.word_tokenize(sherlock_holmes_part_of_text)\n",
    "print(words_nltk[:20])\n",
    "print(f\"Number of words based on NLTK: {len(words_nltk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb63bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', 'Sherlock_Holmes', 'she', 'is', 'always', '_the_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any_other_name']\n",
      "Number of words based on NLTK MWE Tokenizer: 227\n"
     ]
    }
   ],
   "source": [
    "# NLTK's MWE (Multi-Word Expression) tokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "mwe_tokenizer = MWETokenizer([(\"Sherlock\", \"Holmes\")])\n",
    "mwe_tokenizer.add_mwe((\"any\", \"other\", \"name\"))\n",
    "print(mwe_tokenizer.tokenize(words_nltk[:20]))\n",
    "print(\n",
    "    f\"Number of words based on NLTK MWE Tokenizer: {len(mwe_tokenizer.tokenize(words_nltk))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_', 'the', '_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', '\\n', 'mention', 'her', 'under']\n",
      "Number of words based on spaCy: 251\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization using spaCy (reusing nlp model loaded earlier)\n",
    "doc = nlp(sherlock_holmes_part_of_text)\n",
    "words_spacy = [token.text for token in doc]\n",
    "print(words_spacy[:20])\n",
    "print(\n",
    "    f\"Number of words based on spaCy: {len(words_spacy)}\"\n",
    ")  # different from NLTK due to different tokenization rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5195f833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'excellent', '—', 'high', 'power', '’s', 'observer', '_', '-', '\\n'}\n",
      "{'_the_', '’', 'high-power', 's', 'observer—excellent'}\n"
     ]
    }
   ],
   "source": [
    "# Difference between NLTK and spaCy tokenization\n",
    "print(set(words_spacy) - set(words_nltk))\n",
    "print(set(words_nltk) - set(words_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a39373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging with spaCy\n",
    "def pos_tag_spacy(text, model):\n",
    "    doc = model(text)\n",
    "    words = [token.text for token in doc]\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    return list(zip(words, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bff35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('To', 'ADP'), ('Sherlock', 'PROPN'), ('Holmes', 'PROPN'), ('she', 'PRON'), ('is', 'AUX')]\n"
     ]
    }
   ],
   "source": [
    "words_with_pos = pos_tag_spacy(sherlock_holmes_part_of_text, nlp)\n",
    "print(words_with_pos[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('To', 'TO'), ('Sherlock', 'NNP'), ('Holmes', 'NNP'), ('she', 'PRP'), ('is', 'VBZ')]\n"
     ]
    }
   ],
   "source": [
    "# POS tagging with NLTK\n",
    "def word_tokenize_nltk(text):\n",
    "    return nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "\n",
    "def pos_tag_nltk(text):\n",
    "    words = word_tokenize_nltk(text)\n",
    "    return nltk.pos_tag(words)\n",
    "\n",
    "\n",
    "words_with_pos_nltk = pos_tag_nltk(sherlock_holmes_part_of_text)\n",
    "print(words_with_pos_nltk[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /mnt/ebs1/yluo/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"tagsets\")\n",
    "nltk.help.upenn_tagset(\"TO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I told my NLP model to “drop by,” and it deleted the preposition.\n"
     ]
    }
   ],
   "source": [
    "# Experiment with OpenAI's API\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\", input=\"Write a one-sentence joke about NLP.\"\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0adc2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Decide what the part of speech tags are for a sentence.\n",
    "Preserve original capitalizaion.\n",
    "Return the list in the format of a python tuple: (word, part of speech tag).\n",
    "Sentence: In his eyes she eclipses and predominates the whole of her sex.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebf852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Cdq4KAEWCcGgA9rtW0lk5cHUxIOlD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are the part of speech tags for the sentence \"In his eyes she eclipses and predominates the whole of her sex\":\\n\\n```python\\n[(\\'In\\', \\'IN\\'), (\\'his\\', \\'PRP$\\'), (\\'eyes\\', \\'NNS\\'), (\\'she\\', \\'PRP\\'), (\\'eclipses\\', \\'VBZ\\'), (\\'and\\', \\'CC\\'), (\\'predominates\\', \\'VBZ\\'), (\\'the\\', \\'DT\\'), (\\'whole\\', \\'JJ\\'), (\\'of\\', \\'IN\\'), (\\'her\\', \\'PRP$\\'), (\\'sex\\', \\'NN\\')]\\n```\\n\\nIn the above list, each tuple contains a word from the sentence along with its corresponding part of speech tag.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763610980, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=139, prompt_tokens=81, total_tokens=220, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# GPT-3.5-Turbo call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a NLP expert who is also proficient in Python programming.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f4ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the part of speech tags for the sentence \"In his eyes she eclipses and predominates the whole of her sex\":\n",
      "\n",
      "```python\n",
      "[('In', 'IN'), ('his', 'PRP$'), ('eyes', 'NNS'), ('she', 'PRP'), ('eclipses', 'VBZ'), ('and', 'CC'), ('predominates', 'VBZ'), ('the', 'DT'), ('whole', 'JJ'), ('of', 'IN'), ('her', 'PRP$'), ('sex', 'NN')]\n",
      "```\n",
      "\n",
      "In the above list, each tuple contains a word from the sentence along with its corresponding part of speech tag.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99dc6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the part of speech tags for each word in the given sentence, we can use a standardized tag set, such as the Penn Treebank POS tags. Below is the list:\n",
      "\n",
      "```python\n",
      "[\n",
      "    (\"In\", \"IN\"),          # Preposition or subordinating conjunction\n",
      "    (\"his\", \"PRP$\"),       # Possessive pronoun\n",
      "    (\"eyes\", \"NNS\"),       # Noun, plural\n",
      "    (\"she\", \"PRP\"),        # Personal pronoun\n",
      "    (\"eclipses\", \"VBZ\"),   # Verb, third person singular present\n",
      "    (\"and\", \"CC\"),         # Coordinating conjunction\n",
      "    (\"predominates\", \"VBZ\"),  # Verb, third person singular present\n",
      "    (\"the\", \"DT\"),         # Determiner\n",
      "    (\"whole\", \"JJ\"),       # Adjective\n",
      "    (\"of\", \"IN\"),          # Preposition or subordinating conjunction\n",
      "    (\"her\", \"PRP$\"),       # Possessive pronoun\n",
      "    (\"sex\", \"NN\"),         # Noun, singular or mass\n",
      "    (\".\", \".\")             # Punctuation\n",
      "]\n",
      "```\n",
      "\n",
      "This is a simple interpretation based on common part of speech tags. Different tag\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # gpt-5 doesn't exist; use gpt-4o (latest)\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an NLP expert who is also proficient in Python programming.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"In\", \"IN\"),\n",
      "(\"his\", \"PRP$\"),\n",
      "(\"eyes\", \"NNS\"),\n",
      "(\"she\", \"PRP\"),\n",
      "(\"eclipses\", \"VBZ\"),\n",
      "(\"and\", \"CC\"),\n",
      "(\"predominates\", \"VBZ\"),\n",
      "(\"the\", \"DT\"),\n",
      "(\"whole\", \"JJ\"),\n",
      "(\"of\", \"IN\"),\n",
      "(\"her\", \"PRP$\"),\n",
      "(\"sex\", \"NN\"),\n",
      "(\".\", \".\")\n"
     ]
    }
   ],
   "source": [
    "# GPT-5.1 call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an NLP expert who is also proficient in Python programming.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    max_completion_tokens=256,  # Changed from max_tokens\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# response is the full API response object containing metadata and the generated content\n",
    "# .choices[0] is the first list of generated completions (if you set n>0, there are n choices)\n",
    "# .message is the assistant's reply message\n",
    "# .content is the generated tuple of words and POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare differnt model outputs\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "def pos_tag_gpt(text, client):\n",
    "    prompt = f\"\"\"Decide what the part of speech tags are for a sentence.\n",
    "Preserve original capitalizaion.\n",
    "Return the list in the format of a python tuple: (word, part of speech tag).\n",
    "Do not include other explanations.\n",
    "Sentence: {text}\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an NLP expert who is also proficient in Python programming.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_completion_tokens=256,\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    result = result.replace(\"\\n\", \" \")  # Remove newlines\n",
    "    result = list(literal_eval(result))  # Safely evaluate string to list\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60000e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('his', 'PRP$'), ('eyes', 'NNS'), ('she', 'PRP'), ('eclipses', 'VBZ'), ('and', 'CC'), ('predominates', 'VBZ'), ('the', 'DT'), ('whole', 'JJ'), ('of', 'IN'), ('her', 'PRP$'), ('sex', 'NN'), ('.', '.')]\n",
      "GPT-5.1 POS tagging took 2.3951 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "first_sentence = \"In his eyes she eclipses and predominates the whole of her sex.\"\n",
    "words_with_pos = pos_tag_gpt(first_sentence, client)\n",
    "print(words_with_pos)\n",
    "print(f\"GPT-5.1 POS tagging took {time.time() - start:.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d71044d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: running\n",
      "jumps: jump\n",
      "easily: easily\n",
      "fair: fair\n",
      "fairly: fairly\n",
      "wolves: wolf\n",
      "better: well\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "words = [\"running\", \"jumps\", \"easily\", \"fair\", \"fairly\", \"wolves\", \"better\"]\n",
    "doc = nlp(\" \".join(words))\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e1b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: to\n",
      "Sherlock: Sherlock\n",
      "Holmes: Holmes\n",
      "she: she\n",
      "is: be\n",
      "always: always\n",
      "_: _\n",
      "the: the\n",
      "_: _\n",
      "woman: woman\n",
      ".: .\n",
      "I: I\n",
      "have: have\n",
      "seldom: seldom\n",
      "heard: hear\n",
      "him: he\n",
      "\n",
      ": \n",
      "\n",
      "mention: mention\n",
      "her: she\n",
      "under: under\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sherlock_holmes_part_of_text)\n",
    "for token in doc[:20]:\n",
    "    print(f\"{token.text}: {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "353c06f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To is in its base form: False\n",
      "Sherlock is in its base form: False\n",
      "Holmes is in its base form: False\n",
      "she is in its base form: False\n",
      "is is in its base form: False\n",
      "always is in its base form: False\n",
      "_ is in its base form: False\n",
      "the is in its base form: False\n",
      "_ is in its base form: False\n",
      "woman is in its base form: True\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = None\n",
    "for name, proc in nlp.pipeline:\n",
    "    if name == \"lemmatizer\":\n",
    "        lemmatizer = proc\n",
    "\n",
    "for token in doc[:10]:\n",
    "    print(f\"{token} is in its base form: {lemmatizer.is_base_form(token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9652b688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /mnt/ebs1/yluo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using NLTK to remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58ef1be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\")[:10])  # Print first 10 stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3133f0ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m words_nltk = \u001b[43mnltk\u001b[49m.tokenize.word_tokenize(sherlock_holmes_part_of_text)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words_nltk))\n",
      "\u001b[31mNameError\u001b[39m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "words_nltk = nltk.tokenize.word_tokenize(sherlock_holmes_part_of_text)\n",
    "print(len(words_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed0dcce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words_nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m words_ex_stopwords_nltk = [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwords_nltk\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m word.lower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords.words(\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words_ex_stopwords_nltk))\n",
      "\u001b[31mNameError\u001b[39m: name 'words_nltk' is not defined"
     ]
    }
   ],
   "source": [
    "words_ex_stopwords_nltk = [word for word in words_nltk if word.lower() not in stopwords.words(\"english\")]\n",
    "print(len(words_ex_stopwords_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8fcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (learning_python)",
   "language": "python",
   "name": "learning_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
