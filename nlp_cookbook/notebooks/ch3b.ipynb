{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61714976",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"../util/file_utils.ipynb\"\n",
    "%run -i \"../util/lang_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "554d04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df, test_df) = load_train_test_dataset_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2ff5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW vectorizer\n",
    "%run -i \"../util/util_simple_classifier.ipynb\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53c47ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 32789 stored elements and shape (2560, 8842)>\n",
      "  Coords\tValues\n",
      "  (0, 6568)\t1\n",
      "  (0, 2103)\t1\n",
      "  (0, 715)\t1\n",
      "  (0, 42)\t1\n",
      "  (0, 1277)\t1\n",
      "  (0, 5250)\t1\n",
      "  (0, 1604)\t1\n",
      "  (0, 3625)\t1\n",
      "  (0, 3401)\t1\n",
      "  (0, 4750)\t1\n",
      "  (0, 7335)\t1\n",
      "  (0, 2704)\t1\n",
      "  (0, 3471)\t1\n",
      "  (0, 7873)\t1\n",
      "  (0, 486)\t1\n",
      "  (0, 6759)\t1\n",
      "  (0, 4260)\t1\n",
      "  (0, 1438)\t1\n",
      "  (0, 8392)\t1\n",
      "  (0, 1886)\t1\n",
      "  (0, 5456)\t1\n",
      "  (0, 7451)\t1\n",
      "  (0, 6834)\t1\n",
      "  (1, 3425)\t1\n",
      "  (1, 2490)\t1\n",
      "  :\t:\n",
      "  (2557, 8346)\t1\n",
      "  (2557, 5340)\t1\n",
      "  (2557, 8731)\t1\n",
      "  (2557, 5895)\t1\n",
      "  (2557, 3590)\t1\n",
      "  (2557, 6735)\t1\n",
      "  (2557, 1021)\t1\n",
      "  (2557, 5249)\t1\n",
      "  (2558, 5321)\t1\n",
      "  (2558, 6723)\t1\n",
      "  (2558, 968)\t1\n",
      "  (2558, 4144)\t1\n",
      "  (2558, 872)\t1\n",
      "  (2559, 285)\t1\n",
      "  (2559, 5282)\t1\n",
      "  (2559, 6268)\t1\n",
      "  (2559, 5316)\t1\n",
      "  (2559, 7917)\t1\n",
      "  (2559, 3331)\t1\n",
      "  (2559, 5612)\t1\n",
      "  (2559, 6738)\t1\n",
      "  (2559, 8616)\t1\n",
      "  (2559, 7904)\t1\n",
      "  (2559, 1676)\t1\n",
      "  (2559, 5894)\t1\n"
     ]
    }
   ],
   "source": [
    "(train_df, text_df) = load_train_test_dataset_pd()\n",
    "vectorizer = CountVectorizer(max_df=0.1)\n",
    "X = vectorizer.fit_transform(train_df[\"text\"])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3927bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "dense_matrix = X.todense()\n",
    "print(dense_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a65ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '100' '101' ... 'zone' 'ótimo' 'últimos']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "261f52cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8842\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "137f0240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d298772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n"
     ]
    }
   ],
   "source": [
    "first_review = test_df['text'].iat[0]\n",
    "print(first_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09d1194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 11 stored elements and shape (1, 8842)>\n",
      "  Coords\tValues\n",
      "  (0, 953)\t1\n",
      "  (0, 4442)\t1\n",
      "  (0, 4553)\t1\n",
      "  (0, 4613)\t1\n",
      "  (0, 4679)\t1\n",
      "  (0, 4770)\t1\n",
      "  (0, 4783)\t1\n",
      "  (0, 5754)\t1\n",
      "  (0, 7537)\t1\n",
      "  (0, 7705)\t1\n",
      "  (0, 8720)\t1\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sparse_vector = vectorizer.transform([first_review])\n",
    "print(sparse_vector)\n",
    "dense_vector = sparse_vector.todense()\n",
    "print(dense_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9583c2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=300)\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "print(vectorizer.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd6d78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'this', 'film', 'for', 'it', 'an', 'of', 'that', 'movie']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=['the', 'this', 'film', 'for', 'it',\n",
    "                                         'an', 'of', 'that', 'movie'])\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "print(vectorizer.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9a7903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "frozenset({'be', 'now', 'thereupon', 'thin', 'anyhow', 'fill', 'but', 're', 'much', 'again', 'amongst', 'couldnt', 'can', 'fifteen', 'part', 'wherever', 'you', 'co', 'detail', 'herself', 'third', 'once', 'elsewhere', 'could', 'empty', 'other', 'meanwhile', 'some', 'throughout', 'sometime', 'everyone', 'etc', 'everywhere', 'anywhere', 'hundred', 'in', 'anything', 'amoungst', 'upon', 'fire', 'whether', 'because', 'what', 'cant', 'wherein', 'others', 'whither', 'of', 'anyone', 'hereby', 'might', 'around', 'am', 'my', 'their', 'between', 'enough', 'find', 'into', 'well', 'or', 'go', 'few', 'keep', 'any', 'its', 'however', 'even', 'why', 'whereupon', 'found', 'everything', 'whatever', 'becomes', 'eg', 'with', 'towards', 'nobody', 'anyway', 'your', 'there', 'mostly', 'forty', 'across', 'several', 'ten', 'her', 'must', 'whole', 'and', 'me', 'inc', 'take', 'per', 'to', 'last', 'every', 'had', 'name', 'serious', 'bill', 'never', 'behind', 'first', 'may', 'onto', 'back', 'should', 'yours', 'mine', 'afterwards', 'will', 'whose', 'perhaps', 'via', 'this', 'nothing', 'itself', 'whom', 'very', 'eleven', 'seemed', 'side', 'something', 'over', 'against', 'most', 'down', 'nor', 'thru', 'cannot', 'since', 'less', 'became', 'through', 'whereas', 'bottom', 'front', 'more', 'yet', 'until', 'himself', 'thick', 'please', 'themselves', 'they', 'describe', 'fifty', 'myself', 'interest', 'are', 'under', 'from', 'is', 'latterly', 'besides', 'nine', 'where', 'then', 'which', 'such', 'on', 'would', 'full', 'ltd', 'seem', 'ourselves', 'further', 'many', 'next', 'after', 'toward', 'still', 'too', 'twenty', 'alone', 'beforehand', 'neither', 'else', 'someone', 'he', 'thus', 'him', 'his', 'latter', 'seems', 'within', 'de', 'us', 'namely', 'how', 'ever', 'whoever', 'call', 'each', 'sincere', 'have', 'one', 'above', 'cry', 'indeed', 'done', 'thereafter', 'a', 'top', 'by', 'if', 'an', 'put', 'without', 'thence', 'whereafter', 'she', 'these', 'along', 'up', 'same', 'un', 'ours', 'the', 'both', 'get', 'least', 'otherwise', 'somewhere', 'it', 'due', 'yourself', 'when', 'below', 'show', 'beyond', 'move', 'together', 'hers', 'who', 'eight', 'among', 'see', 'while', 'six', 'seeming', 'three', 'no', 'sometimes', 'only', 'hence', 'thereby', 'although', 'whenever', 'been', 'for', 'that', 'those', 'here', 'were', 'yourselves', 'therefore', 'so', 'herein', 'them', 'twelve', 'become', 'noone', 'beside', 'as', 'always', 'rather', 'five', 'we', 'already', 'none', 'therein', 'two', 'during', 'whereby', 'formerly', 'four', 'has', 'another', 'nowhere', 'all', 'though', 'hasnt', 'either', 'out', 'own', 'somehow', 'not', 'moreover', 'i', 'made', 'mill', 'our', 'also', 'off', 'amount', 'whence', 'at', 'sixty', 'about', 'was', 'being', 'almost', 'do', 'than', 'except', 'before', 'con', 'hereupon', 'nevertheless', 'system', 'becoming', 'give', 'hereafter', 'former', 'often', 'ie'})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Add your domain-specific stop words\n",
    "my_stop_words = list(ENGLISH_STOP_WORDS) + ['covid', 'pandemic', 'said']\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=my_stop_words)\n",
    "X = vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# Verify custom stops were used\n",
    "print(len(my_stop_words))  # ~321 words\n",
    "\n",
    "print(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38a0827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       160\n",
      "           1       0.73      0.74      0.74       160\n",
      "\n",
      "    accuracy                           0.73       320\n",
      "   macro avg       0.73      0.73      0.73       320\n",
      "weighted avg       0.73      0.73      0.73       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "(train_df, test_df) = load_train_test_dataset_pd() # load_train_test_dataset_pd is a custom function\n",
    "vectorizer = CountVectorizer(max_df=0.8) # need to add stop_words\n",
    "X = vectorizer.fit_transform(train_df[\"text\"])\n",
    "vectorize = lambda x: vectorizer.transform([x]).toarray()[0]\n",
    "(X_train, X_test, y_train, y_test) = create_train_test_data(\n",
    "    train_df, test_df, vectorize\n",
    ")\n",
    "clf = train_classifier(X_train, y_train)\n",
    "test_classifier(test_df, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77dd37e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '10 inch' '10 set' ... 'ótimo esforço' 'últimos' 'últimos tiempos']\n",
      "40552\n"
     ]
    }
   ],
   "source": [
    "# Bigram vectorizer\n",
    "bigram_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1,2), max_df=0.8)\n",
    "X = bigram_vectorizer.fit_transform(train_df['text'])\n",
    "print(bigram_vectorizer.get_feature_names_out())\n",
    "print(len(bigram_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14554496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       160\n",
      "           1       0.74      0.71      0.73       160\n",
      "\n",
      "    accuracy                           0.73       320\n",
      "   macro avg       0.73      0.73      0.73       320\n",
      "weighted avg       0.73      0.73      0.73       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1. Create and fit bigram vectorizer\n",
    "bigram_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),  # Unigrams + bigrams\n",
    "    max_df=0.8,          # Remove high-frequency terms\n",
    ")\n",
    "X = bigram_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# 2. Define vectorization function\n",
    "def vectorize_bigram(text):\n",
    "    \"\"\"Vectorize a single text string\"\"\"\n",
    "    return bigram_vectorizer.transform([text]).toarray()[0]\n",
    "\n",
    "# 3. Create train/test data\n",
    "(X_train, X_test, y_train, y_test) = create_train_test_data(\n",
    "    train_df, test_df, vectorize_bigram\n",
    ")\n",
    "\n",
    "# 4. Train classifier\n",
    "clf = train_classifier(X_train, y_train)\n",
    "\n",
    "# 5. Test classifier\n",
    "test_classifier(test_df, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d95429ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       160\n",
      "           1       0.73      0.74      0.74       160\n",
      "\n",
      "    accuracy                           0.73       320\n",
      "   macro avg       0.73      0.73      0.73       320\n",
      "weighted avg       0.73      0.73      0.73       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1. Create and fit bigram vectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.8)\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# 2. Define vectorization function\n",
    "def vectorize(text):\n",
    "    \"\"\"Vectorize a single text string\"\"\"\n",
    "    return vectorizer.transform([text]).toarray()[0]\n",
    "\n",
    "# 3. Create train/test data\n",
    "(X_train, X_test, y_train, y_test) = create_train_test_data(\n",
    "    train_df, test_df, vectorize\n",
    ")\n",
    "\n",
    "# 4. Train classifier\n",
    "clf = train_classifier(X_train, y_train)\n",
    "\n",
    "# 5. Test classifier\n",
    "test_classifier(test_df, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41051e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       160\n",
      "           1       0.74      0.78      0.76       160\n",
      "\n",
      "    accuracy                           0.75       320\n",
      "   macro avg       0.75      0.75      0.75       320\n",
      "weighted avg       0.75      0.75      0.75       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Create and fit vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=300)\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# 2. Define vectorization function\n",
    "def vectorize(text):\n",
    "    \"\"\"Vectorize a single text string\"\"\"\n",
    "    return vectorizer.transform([text]).toarray()[0]\n",
    "\n",
    "# 3. Create train/test data\n",
    "(X_train, X_test, y_train, y_test) = create_train_test_data(\n",
    "    train_df, test_df, vectorize\n",
    ")\n",
    "\n",
    "# 4. Train classifier\n",
    "clf = train_classifier(X_train, y_train)\n",
    "\n",
    "# 5. Test classifier\n",
    "test_classifier(test_df, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50406833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       160\n",
      "           1       0.74      0.74      0.74       160\n",
      "\n",
      "    accuracy                           0.74       320\n",
      "   macro avg       0.74      0.74      0.74       320\n",
      "weighted avg       0.74      0.74      0.74       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Create and fit vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(1,5))\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# 2. Define vectorization function\n",
    "def vectorize(text):\n",
    "    \"\"\"Vectorize a single text string\"\"\"\n",
    "    return vectorizer.transform([text]).toarray()[0]\n",
    "\n",
    "# 3. Create train/test data\n",
    "(X_train, X_test, y_train, y_test) = create_train_test_data(\n",
    "    train_df, test_df, vectorize\n",
    ")\n",
    "\n",
    "# 4. Train classifier\n",
    "clf = train_classifier(X_train, y_train)\n",
    "\n",
    "# 5. Test classifier\n",
    "test_classifier(test_df, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250a6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
