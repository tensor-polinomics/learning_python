{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f882d0b",
   "metadata": {},
   "source": [
    "# Fine-tuned BERT Model for NER on Music Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401583c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"../util/lang_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d018480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    load_dataset, Dataset, Features, Value,\n",
    "    ClassLabel, Sequence, DatasetDict)\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification, TrainingArguments, Trainer)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c6927b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13434</td>\n",
       "      <td>i love radioheads kid a something similar ,  k...</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>Artist_known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13434</td>\n",
       "      <td>i love radioheads kid a something similar ,  k...</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>Artist_or_WoA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13435</td>\n",
       "      <td>anything similar to i fight dragons</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>WoA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13436</td>\n",
       "      <td>music similar to ccrs travelin band</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>Artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13437</td>\n",
       "      <td>songs similar to blackout by boris</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>WoA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  start_offset  \\\n",
       "0  13434  i love radioheads kid a something similar ,  k...             7   \n",
       "1  13434  i love radioheads kid a something similar ,  k...            61   \n",
       "2  13435                anything similar to i fight dragons            20   \n",
       "3  13436                music similar to ccrs travelin band            17   \n",
       "4  13437                 songs similar to blackout by boris            17   \n",
       "\n",
       "   end_offset          label  \n",
       "0          17   Artist_known  \n",
       "1          71  Artist_or_WoA  \n",
       "2          35            WoA  \n",
       "3          30         Artist  \n",
       "4          25            WoA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_ner_df = pd.read_csv(\"../data/music_ner.csv\")\n",
    "def change_label(input_label):\n",
    "    input_label = input_label.replace(\"_deduced\", \"\")\n",
    "    return input_label\n",
    "music_ner_df[\"label\"] = music_ner_df[\"label\"].apply(change_label)\n",
    "music_ner_df[\"text\"] = music_ner_df[\"text\"].apply(lambda x: x.replace(\"|\", \", \"))\n",
    "music_ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d890fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "ids = list(set(music_ner_df[\"id\"].values))\n",
    "docs = {}\n",
    "for id in ids:\n",
    "    entity_rows = music_ner_df[music_ner_df[\"id\"]==id]\n",
    "    text = entity_rows.head(1)[\"text\"].values[0]\n",
    "    doc = small_model(text)\n",
    "    ents = []\n",
    "    for _, row in entity_rows.iterrows():\n",
    "        start = row[\"start_offset\"]\n",
    "        end = row[\"end_offset\"]\n",
    "        label = row[\"label\"]\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    docs[doc.text] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses data into tokens; maps NER tags to integers, reconstructs sentences, \n",
    "# Extracts the predicted entity spans\n",
    "data_file = \"../data/music_ner_bio.bio\"\n",
    "tag_mapping = {\"O\": 0, \"B-Artist\": 1, \"I-Artist\": 2, \"B-WoA\": 3, \"I-WoA\": 4}\n",
    "with open(data_file, \"r\") as f:\n",
    "    data = f.read()\n",
    "tokens = [] # word lists per sentence\n",
    "ner_tags = [] # integer NER tag lists per sentence\n",
    "spans = [] # extracted entity spans per sentence\n",
    "sentences = data.split(\"\\n\\n\")\n",
    "for sentence in sentences:\n",
    "    words = [] # words in this sentence\n",
    "    tags = [] # integer NER tags in this sentence\n",
    "    this_sentence_spans = [] # NER spans from model output\n",
    "    word_tag_pairs = sentence.split(\"\\n\") # word-tag pairs, separated by <TAB>\n",
    "    for pair in word_tag_pairs:\n",
    "        (word, tag) = pair.split(\"\\t\")\n",
    "        words.append(word)\n",
    "        tags.append(tag_mapping[tag])\n",
    "    sentences_text = \" \".join(words)\n",
    "    try:\n",
    "        doc = docs[sentences_text]\n",
    "    except:\n",
    "        pass\n",
    "    ent_dict = {}\n",
    "    for ent in doc.ents:\n",
    "        this_sentence_spans.append(f\"{ent.label_}: {ent.text}\")\n",
    "    tokens.append(words)\n",
    "    ner_tags.append(tags)\n",
    "    spans.append(this_sentence_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24796c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539 60\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "indices = range(0, len(spans))\n",
    "train, test = train_test_split(indices, test_size=0.1)\n",
    "train_tokens = []\n",
    "train_ner_tags = []\n",
    "train_spans = []\n",
    "test_tokens = []\n",
    "test_ner_tags = []\n",
    "test_spans = []\n",
    "for i, (toke, ner_tag, span) in enumerate(zip(tokens, ner_tags, spans)):\n",
    "    if i in train:\n",
    "        train_tokens.append(toke)\n",
    "        train_ner_tags.append(ner_tag)\n",
    "        train_spans.append(span)\n",
    "    else:\n",
    "        test_tokens.append(toke)\n",
    "        test_ner_tags.append(ner_tag)\n",
    "        test_spans.append(span)\n",
    "print(len(train_tokens), len(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa76d64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[anything, similar, to, i, fight, dragons]</td>\n",
       "      <td>[0, 0, 0, 1, 2, 2]</td>\n",
       "      <td>[WoA: i fight dragons]</td>\n",
       "      <td>anything similar to i fight dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[music, similar, to, ccrs, travelin, band]</td>\n",
       "      <td>[0, 0, 0, 1, 3, 4]</td>\n",
       "      <td>[Artist: ccrs travelin]</td>\n",
       "      <td>music similar to ccrs travelin band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[songs, similar, to, blackout, by, boris]</td>\n",
       "      <td>[0, 0, 0, 3, 0, 1]</td>\n",
       "      <td>[WoA: blackout, Artist: boris]</td>\n",
       "      <td>songs similar to blackout by boris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[songs, similar, to, trios, da, da, da]</td>\n",
       "      <td>[0, 0, 0, 1, 3, 4, 4]</td>\n",
       "      <td>[Artist_known: trios, WoA: da da da]</td>\n",
       "      <td>songs similar to trios da da da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[aything, similar, to, radioheads, everything,...</td>\n",
       "      <td>[0, 0, 0, 1, 3, 4, 4, 4, 4]</td>\n",
       "      <td>[Artist_known: radioheads, WoA: everything in ...</td>\n",
       "      <td>aything similar to radioheads everything in it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0         [anything, similar, to, i, fight, dragons]   \n",
       "1         [music, similar, to, ccrs, travelin, band]   \n",
       "2          [songs, similar, to, blackout, by, boris]   \n",
       "3            [songs, similar, to, trios, da, da, da]   \n",
       "4  [aything, similar, to, radioheads, everything,...   \n",
       "\n",
       "                      ner_tags  \\\n",
       "0           [0, 0, 0, 1, 2, 2]   \n",
       "1           [0, 0, 0, 1, 3, 4]   \n",
       "2           [0, 0, 0, 3, 0, 1]   \n",
       "3        [0, 0, 0, 1, 3, 4, 4]   \n",
       "4  [0, 0, 0, 1, 3, 4, 4, 4, 4]   \n",
       "\n",
       "                                               spans  \\\n",
       "0                             [WoA: i fight dragons]   \n",
       "1                            [Artist: ccrs travelin]   \n",
       "2                     [WoA: blackout, Artist: boris]   \n",
       "3               [Artist_known: trios, WoA: da da da]   \n",
       "4  [Artist_known: radioheads, WoA: everything in ...   \n",
       "\n",
       "                                                text  \n",
       "0                anything similar to i fight dragons  \n",
       "1                music similar to ccrs travelin band  \n",
       "2                 songs similar to blackout by boris  \n",
       "3                    songs similar to trios da da da  \n",
       "4  aything similar to radioheads everything in it...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.DataFrame({\"tokens\":train_tokens,\n",
    "                            \"ner_tags\":train_ner_tags,\n",
    "                            \"spans\":train_spans})\n",
    "testing_df = pd.DataFrame({\"tokens\":test_tokens,\n",
    "                           \"ner_tags\":test_ner_tags,\n",
    "                           \"spans\":test_spans})\n",
    "training_df[\"text\"] = training_df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "testing_df[\"text\"] = testing_df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "training_df.dropna(inplace=True)\n",
    "testing_df.dropna(inplace=True)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33941de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': List(Value('string')), 'ner_tags': List(ClassLabel(names=['O', 'B-Artist', 'I-Artist', 'B-WoA', 'I-WoA'])), 'spans': List(Value('string')), 'text': Value('string')}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'spans', 'text'],\n",
      "        num_rows: 539\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'spans', 'text'],\n",
      "        num_rows: 60\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "features = Features({\n",
    "    \"tokens\": Sequence(feature=Value(dtype=\"string\", id=None),\n",
    "                       length=-1, id=None),\n",
    "    \"ner_tags\": Sequence(feature=ClassLabel(names=[\"O\", \"B-Artist\", \"I-Artist\", \"B-WoA\", \"I-WoA\"]),\n",
    "                         length=-1, id=None),\n",
    "    \"spans\": Sequence(feature=Value(dtype=\"string\", id=None),\n",
    "                      length=-1, id=None),\n",
    "    \"text\": Value(dtype=\"string\", id=None)\n",
    "})\n",
    "training_dataset = Dataset.from_pandas(training_df, features=features)\n",
    "testing_dataset = Dataset.from_pandas(testing_df, features=features)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": training_dataset,\n",
    "    \"test\": testing_dataset\n",
    "})\n",
    "print(dataset[\"train\"].features)\n",
    "label_names = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a5113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_adjust_labels(all_samples_per_split):\n",
    "    tokenized_samples = tokenizer.batch_encode_plus(\n",
    "        all_samples_per_split[\"text\"])\n",
    "    total_adjusted_labels = []\n",
    "    for k in range(0, len(tokenized_samples[\"input_ids\"])):\n",
    "        prev_wid = -1\n",
    "        word_ids_list = tokenized_samples.word_ids(batch_index=k)\n",
    "        existing_label_ids = all_samples_per_split[\"ner_tags\"][k]\n",
    "        i = -1\n",
    "        adjusted_label_ids = []\n",
    "        for wid in word_ids_list:\n",
    "            if wid is None:\n",
    "                adjusted_label_ids.append(-100)\n",
    "            elif wid != prev_wid:\n",
    "                i += 1\n",
    "                adjusted_label_ids.append(existing_label_ids[i])\n",
    "                prev_wid = wid\n",
    "            else:\n",
    "                label_name = label_names[existing_label_ids[i]]\n",
    "                adjusted_label_ids.append(existing_label_ids[i])\n",
    "        total_adjusted_labels.append(adjusted_label_ids)\n",
    "    tokenized_samples[\"labels\"] = total_adjusted_labels\n",
    "    return tokenized_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37424d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8c80994c4a4248977061bc734dffd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d05fd4398c44358651714c333a908c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_adjust_labels,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d66dcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c31405f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bcaa9fb7ff498f9253f93ff46583e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load(\"seqeval\")\n",
    "def compute_metrics(data):\n",
    "    predictions, labels = data\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    data = zip(predictions, labels)\n",
    "    data = [\n",
    "        [(p, l) for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in data\n",
    "    ]\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in data_point]\n",
    "        for data_point in data\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_names[l] for (p, l) in data_point]\n",
    "        for data_point in data\n",
    "    ]\n",
    "    \n",
    "    results = metric.compute(predictions=true_predictions,\n",
    "                             references=true_labels)\n",
    "    flat_results = {\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    for k in results.keys():\n",
    "        if (k not in flat_results.keys()):\n",
    "            flat_results[k + \"_f1\"] = results[k][\"f1\"]\n",
    "    return flat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b2a00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2760222/2257682509.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/mnt/ebs1/yluo/projects/learning/learning_python/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 06:13, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=238, training_loss=0.25610123962915243, metrics={'train_runtime': 376.9644, 'train_samples_per_second': 10.009, 'train_steps_per_second': 0.631, 'total_flos': 50108074210740.0, 'train_loss': 0.25610123962915243, 'epoch': 7.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(label_names))\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tune_bert_output\",\n",
    "    eval_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1000,\n",
    "    run_name=\"ep_10_tokenized_l1\",\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da703e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ebs1/yluo/projects/learning/learning_python/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2008223682641983,\n",
       " 'eval_overall_precision': 0.5444444444444444,\n",
       " 'eval_overall_recall': 0.6125,\n",
       " 'eval_overall_f1': 0.5764705882352941,\n",
       " 'eval_overall_accuracy': 0.9241935483870968,\n",
       " 'eval_Artist_f1': 0.5739130434782609,\n",
       " 'eval_WoA_f1': 0.5818181818181819,\n",
       " 'eval_runtime': 2.7652,\n",
       " 'eval_samples_per_second': 21.698,\n",
       " 'eval_steps_per_second': 1.447,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "928e7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/bert_fine_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "571d9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"../models/bert_fine_tuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/bert_fine_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f47ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'LABEL_0', 'score': np.float32(0.9992376), 'word': 'music similar to', 'start': 0, 'end': 16}\n",
      "{'entity_group': 'LABEL_1', 'score': np.float32(0.855024), 'word': 'morphie roboco', 'start': 17, 'end': 31}\n",
      "{'entity_group': 'LABEL_2', 'score': np.float32(0.71867263), 'word': '##bra quartet', 'start': 31, 'end': 42}\n",
      "{'entity_group': 'LABEL_0', 'score': np.float32(0.99892324), 'word': '| featuring elements like saxophone prominent bass', 'start': 43, 'end': 93}\n"
     ]
    }
   ],
   "source": [
    "text = \"music similar to morphie robocobra quartet | featuring elements like saxophone prominent bass\"\n",
    "from transformers import pipeline\n",
    "pipeline = pipeline(\n",
    "    task=\"token-classification\", model=model, tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\")\n",
    "result = pipeline(text)\n",
    "for entity in result:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a68bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
