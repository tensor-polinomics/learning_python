{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29b1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, GenerationConfig)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d87227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Loads from .env file\n",
    "\n",
    "if token := os.getenv(\"HF_TOKEN\"):\n",
    "    login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986c5e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a724ddb6671b435ba81e4815438838b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590148efb4ad4de0977456350813d485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08406b455e8a458fb7f2fe84bd353836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e3b1aa36a442a992cd22ad0b067b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292c14558b8f42fc93d6aa16818a14c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ea23a6c8e4dbb88e4f0bc1ca88c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e196b64d1b54be0990ba7fc00decb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98749f87acf04933891b0579fa38071b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013963b1b2ad435db1ed9f5e2185ab72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3071ae041caf43f58fbc894f065491f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664a972f97e1440c948fc2fd8d53d12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Smaller models that fit more easily\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"  # Or try these alternatives:\n",
    "# model_name = \"microsoft/phi-2\"                   # 2.7B params\n",
    "# model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # 1.1B params\n",
    "# model_name = \"Qwen/Qwen2-1.5B\"                   # 1.5B params\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551e2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the theory of relativity in simple terms.\n",
      "\n",
      "The theory of relativity is a scientific explanation of how space and time are connected. It was first proposed by Albert Einstein in the early 20th century.\n",
      "\n",
      "There are two parts to the theory of relativity: the special theory of relativity and the general theory of relativity.\n",
      "\n",
      "The special theory of relativity states that the laws of physics are the same for all observers moving at a constant speed in a straight line. It also says that the speed of light is always the same, no matter how fast an observer is moving or how far away the light source is. This leads to some strange results, like time slowing down for objects moving at high speeds.\n",
      "\n",
      "The general theory of relativity extends the special theory to include gravity. It says that massive objects cause a distortion in space-time, which is felt as gravity. This means that gravity is not a force between two objects, but rather a curvature of space-time caused by the presence of mass.\n",
      "\n",
      "Overall, the theory of relativity revolutionized our understanding of space and time, and has had many important applications in fields like physics, astronomy, and cosmology.\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    "    max_new_tokens=300,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "seed_sentence = \"Explain the theory of relativity in simple terms.\"\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    [seed_sentence], return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs, generation_config=generation_config)\n",
    "generated_text = tokenizer.batch_decode(\n",
    "    generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1432d3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eec8b9ba534d2f87c1fc17a8fc47b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    "    repetition_penalty=1.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b194386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"What's your favorite book?\"}, {'role': 'assistant', 'content': 'I enjoy reading science fiction novels.'}, {'role': 'user', 'content': 'Can you recommend one?'}, {'role': 'assistant', 'content': ' One of my favorite science fiction novels is \"Dune\" by Frank Herbert.'}]\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"What's your favorite book?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I enjoy reading science fiction novels.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you recommend one?\"},\n",
    "]\n",
    "response = pipe(prompt)\n",
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32181a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a great mentor.\n",
      "Human: What is Python programming?\n",
      "AI: Python is a high-level, interpreted programming language that is widely used for web development, data analysis, artificial intelligence, and machine learning. It is known for its simplicity, readability, and ease of use, making it a popular choice for beginners and experienced programmers alike.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a great mentor.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"input\": \"What is Python programming?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b92a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Answer the question. Keep your answer under 10 words.\n",
      "\n",
      "Question: Who is the president of the United States?\n",
      "Answer: Joe Biden\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question. Keep your answer under 10 words.\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"input\": \"Who is the president of the United States?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344afa99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
