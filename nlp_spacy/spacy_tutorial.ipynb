{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15389c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.14 (main, Oct 31 2025, 23:04:14) [Clang 21.1.4 ]\n",
      "Executable: /mnt/ebs1/yluo/projects/learning/learning_python/.venv/bin/python\n",
      "Kernel: learning_python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Executable: {sys.executable}\")\n",
    "print(f\"Kernel: learning_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82ee0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "a DET det\n",
      "U.K. PROPN dobj\n",
      "startup NOUN advcl\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c01121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844a1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" PUNCT \" False False\n",
      "Let VERB Xxx True False\n",
      "'s PRON 'x False True\n",
      "go VERB xx True True\n",
      "to ADP xx True True\n",
      "N.Y. PROPN X.X. False False\n",
      "! PUNCT ! False False\n",
      "\" PUNCT \" False False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('\"Let\\'s go to N.Y.!\"')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5628c71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, 3rd person singular present'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VBZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d5516dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3525915  -0.5595864   1.3269742  -0.4591393  -0.2378951   0.35304713\n",
      "  0.9810033   0.9120197  -0.7636418   0.53343236  0.7111834  -0.4101859\n",
      " -0.22609742  0.21238515  0.1977409   0.5262209  -1.1578097  -0.6223494\n",
      "  0.04481605 -0.9658006   0.11590984  1.0158504  -0.81331897 -0.06708208\n",
      "  0.46827182  0.55026615  1.0141313   0.18985981 -0.32852772  1.5085963\n",
      " -0.68311155  0.2897485  -0.17085919  0.51104367 -0.41968206 -0.44074327\n",
      " -0.00220814  0.44290805  0.10646416  0.26499194 -0.5972402  -0.17584111\n",
      "  0.09915334  1.245649   -0.0993301   0.03572413 -0.94779813 -0.7312204\n",
      " -0.3475603  -1.3627207   0.16587363 -0.22425665  0.8468491  -1.3706408\n",
      "  1.0920432  -0.5718084   0.7467524  -0.34398675 -0.24239466  0.1408653\n",
      " -0.72588027  0.11295792  0.13626975 -0.8679844   0.21890712 -0.10783374\n",
      "  0.71108097  0.06787673 -0.3360198  -0.547363    0.11034714  0.55276895\n",
      "  0.34893125  0.79479325  0.1372495  -0.5995597  -0.12229609 -0.49462122\n",
      " -0.17136315  0.2365407  -0.7538129  -0.51677805 -0.87205154  0.19488558\n",
      "  1.0055629  -0.06117523  0.5568132   0.17665946 -1.0965905   0.5974612\n",
      " -1.401958    0.93490857  1.0865647   0.2098248  -0.6814435   0.43522495]\n"
     ]
    }
   ],
   "source": [
    "word = nlp(\"intelligence\")\n",
    "print(word.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5baf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1228265/210735532.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  doc1.similarity(doc2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5968894958496094"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"Large language model\")\n",
    "doc2 = nlp(\"artificial intelligence\")\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe9642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8566208034543834098\n",
      "apple\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
    "print(doc.vocab.strings['apple'])\n",
    "print(doc.vocab.strings[8566208034543834098])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e8589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "file_name = pathlib.Path(\"Data/nvidia2025q3.txt\")\n",
    "text = file_name.read_text(encoding=\"utf-8\")\n",
    "nvidia_doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233ee581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nvidia', '(', '\\n', 'NVDA', '\\n', '+2.61', '%', '\\n', ')', '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in nvidia_doc[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb41022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(nvidia_doc.sents)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43e4fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia (\n",
      "NVDA\n",
      "+2.61%\n",
      ")\n",
      "Q3 2025 Earnings Call\n",
      "Nov 20, 2024,\n",
      "My name is Jay, and I'll be your conference operator today.\n",
      "At this time, I would like to welcome everyone to NVIDIA's third-quarter earnings call.\n",
      "All lines have been placed on mute to prevent any background noise.\n",
      "\n",
      "\n",
      "After the speakers' remarks, there will be a question-and-answer session.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[:5]:\n",
    "    print(sentence[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8da2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "about_text = (\n",
    "     \"Gus Proto is a Python developer currently\"\n",
    "     \" working for a London-based Fintech\"\n",
    "     \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcbc1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gus',\n",
       " 'Proto',\n",
       " 'Python',\n",
       " 'developer',\n",
       " 'currently',\n",
       " 'working',\n",
       " 'London',\n",
       " '-',\n",
       " 'based',\n",
       " 'Fintech',\n",
       " 'company',\n",
       " '.',\n",
       " 'interested',\n",
       " 'learning',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about_doc = nlp(about_text)\n",
    "[token.text for token in about_doc if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c7535d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus             0\n",
      "Proto           4\n",
      "is              10\n",
      "a               13\n",
      "Python          15\n",
      "developer       22\n",
      "currently       32\n",
      "working         42\n",
      "for             50\n",
      "a               54\n"
     ]
    }
   ],
   "source": [
    "for token in about_doc[:10]:\n",
    "    print(f\"{token.text:15} {token.idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef778ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ... never mind, I forgot what I was saying.\n",
      "So, do you think we should ... go for lunch?\n"
     ]
    }
   ],
   "source": [
    "ellipsis_text = (\n",
    "    \"Gus, can you, ... never mind, I forgot\"\n",
    "    \" what I was saying. So, do you think\"\n",
    "    \" we should ... go for lunch?\"\n",
    ")\n",
    "ellipsis_doc = nlp(ellipsis_text)\n",
    "ellipsis_sentences = list(ellipsis_doc.sents)\n",
    "for sentence in ellipsis_sentences:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "072f86b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ...\n",
      "never mind, I forgot what I was saying.\n",
      "So, do you think we should ...\n",
      "go for lunch?\n"
     ]
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cb36561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ai', 109), ('nvidia', 60), ('blackwell', 49), ('year', 43), ('data', 43), ('inference', 35), ('new', 34), ('question', 32), ('going', 32), ('quarter', 30)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = [\n",
    "    token.text.lower()\n",
    "    for token in nvidia_doc\n",
    "    if not token.is_stop \n",
    "        and not token.is_punct\n",
    "        and token.text.strip() != \"\"\n",
    "]\n",
    "print(Counter(words).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec204253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (learning_python)",
   "language": "python",
   "name": "learning_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
