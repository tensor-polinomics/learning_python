{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15389c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.14 (main, Oct 31 2025, 23:04:14) [Clang 21.1.4 ]\n",
      "Executable: /mnt/ebs1/yluo/projects/learning/learning_python/.venv/bin/python\n",
      "Kernel: learning_python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Executable: {sys.executable}\")\n",
    "print(f\"Kernel: learning_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82ee0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "a DET det\n",
      "U.K. PROPN dobj\n",
      "startup NOUN advcl\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c01121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "844a1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" PUNCT \" False False\n",
      "Let VERB Xxx True False\n",
      "'s PRON 'x False True\n",
      "go VERB xx True True\n",
      "to ADP xx True True\n",
      "N.Y. PROPN X.X. False False\n",
      "! PUNCT ! False False\n",
      "\" PUNCT \" False False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('\"Let\\'s go to N.Y.!\"')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5628c71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, 3rd person singular present'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VBZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5516dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3525915  -0.5595864   1.3269742  -0.4591393  -0.2378951   0.35304713\n",
      "  0.9810033   0.9120197  -0.7636418   0.53343236  0.7111834  -0.4101859\n",
      " -0.22609742  0.21238515  0.1977409   0.5262209  -1.1578097  -0.6223494\n",
      "  0.04481605 -0.9658006   0.11590984  1.0158504  -0.81331897 -0.06708208\n",
      "  0.46827182  0.55026615  1.0141313   0.18985981 -0.32852772  1.5085963\n",
      " -0.68311155  0.2897485  -0.17085919  0.51104367 -0.41968206 -0.44074327\n",
      " -0.00220814  0.44290805  0.10646416  0.26499194 -0.5972402  -0.17584111\n",
      "  0.09915334  1.245649   -0.0993301   0.03572413 -0.94779813 -0.7312204\n",
      " -0.3475603  -1.3627207   0.16587363 -0.22425665  0.8468491  -1.3706408\n",
      "  1.0920432  -0.5718084   0.7467524  -0.34398675 -0.24239466  0.1408653\n",
      " -0.72588027  0.11295792  0.13626975 -0.8679844   0.21890712 -0.10783374\n",
      "  0.71108097  0.06787673 -0.3360198  -0.547363    0.11034714  0.55276895\n",
      "  0.34893125  0.79479325  0.1372495  -0.5995597  -0.12229609 -0.49462122\n",
      " -0.17136315  0.2365407  -0.7538129  -0.51677805 -0.87205154  0.19488558\n",
      "  1.0055629  -0.06117523  0.5568132   0.17665946 -1.0965905   0.5974612\n",
      " -1.401958    0.93490857  1.0865647   0.2098248  -0.6814435   0.43522495]\n"
     ]
    }
   ],
   "source": [
    "word = nlp(\"intelligence\")\n",
    "print(word.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5baf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1272576/210735532.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  doc1.similarity(doc2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5968894958496094"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"Large language model\")\n",
    "doc2 = nlp(\"artificial intelligence\")\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebe9642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8566208034543834098\n",
      "apple\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
    "print(doc.vocab.strings['apple'])\n",
    "print(doc.vocab.strings[8566208034543834098])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e8589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "file_name = pathlib.Path(\"Data/nvidia2025q3.txt\")\n",
    "text = file_name.read_text(encoding=\"utf-8\")\n",
    "nvidia_doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "233ee581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nvidia', '(', '\\n', 'NVDA', '\\n', '+2.61', '%', '\\n', ')', '\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in nvidia_doc[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cb41022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(nvidia_doc.sents)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43e4fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia (\n",
      "NVDA\n",
      "+2.61%\n",
      ")\n",
      "Q3 2025 Earnings Call\n",
      "Nov 20, 2024,\n",
      "My name is Jay, and I'll be your conference operator today.\n",
      "At this time, I would like to welcome everyone to NVIDIA's third-quarter earnings call.\n",
      "All lines have been placed on mute to prevent any background noise.\n",
      "\n",
      "\n",
      "After the speakers' remarks, there will be a question-and-answer session.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[:5]:\n",
    "    print(sentence[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8da2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "about_text = (\n",
    "     \"Gus Proto is a Python developer currently\"\n",
    "     \" working for a London-based Fintech\"\n",
    "     \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfcbc1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gus',\n",
       " 'Proto',\n",
       " 'Python',\n",
       " 'developer',\n",
       " 'currently',\n",
       " 'working',\n",
       " 'London',\n",
       " '-',\n",
       " 'based',\n",
       " 'Fintech',\n",
       " 'company',\n",
       " '.',\n",
       " 'interested',\n",
       " 'learning',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about_doc = nlp(about_text)\n",
    "[token.text for token in about_doc if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c7535d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus             0\n",
      "Proto           4\n",
      "is              10\n",
      "a               13\n",
      "Python          15\n",
      "developer       22\n",
      "currently       32\n",
      "working         42\n",
      "for             50\n",
      "a               54\n"
     ]
    }
   ],
   "source": [
    "for token in about_doc[:10]:\n",
    "    print(f\"{token.text:15} {token.idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef778ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ... never mind, I forgot what I was saying.\n",
      "So, do you think we should ... go for lunch?\n"
     ]
    }
   ],
   "source": [
    "ellipsis_text = (\n",
    "    \"Gus, can you, ... never mind, I forgot\"\n",
    "    \" what I was saying. So, do you think\"\n",
    "    \" we should ... go for lunch?\"\n",
    ")\n",
    "ellipsis_doc = nlp(ellipsis_text)\n",
    "ellipsis_sentences = list(ellipsis_doc.sents)\n",
    "for sentence in ellipsis_sentences:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072f86b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ...\n",
      "never mind, I forgot what I was saying.\n",
      "So, do you think we should ...\n",
      "go for lunch?\n"
     ]
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cb36561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ai', 109), ('nvidia', 60), ('blackwell', 49), ('year', 43), ('data', 43), ('inference', 35), ('new', 34), ('question', 32), ('going', 32), ('quarter', 30)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = [\n",
    "    token.text.lower()\n",
    "    for token in nvidia_doc\n",
    "    if not token.is_stop \n",
    "        and not token.is_punct\n",
    "        and token.text.strip() != \"\"\n",
    "]\n",
    "print(Counter(words).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec204253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia          NNP             PROPN           proper noun\n",
      "(               -LRB-           PUNCT           punctuation\n",
      "\n",
      "               _SP             SPACE           space\n",
      "NVDA            NNP             PROPN           proper noun\n",
      "\n",
      "               _SP             SPACE           space\n",
      "+2.61           NN              NOUN            noun\n",
      "%               NN              NOUN            noun\n",
      "\n",
      "               _SP             SPACE           space\n",
      ")               -RRB-           PUNCT           punctuation\n",
      "\n",
      "               _SP             SPACE           space\n"
     ]
    }
   ],
   "source": [
    "for token in nvidia_doc[:10]:\n",
    "    print(f\"{token.text:15} {token.tag_:15} {token.pos_:15} {spacy.explain(token.pos_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32e26b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nvidia', 'nvda', '+2.61', 'q3', '2025', 'earnings', 'nov', '20', '2024', '5:00', 'p.m.', 'et', 'content', 'prepare', 'remarks', 'questions', 'answer', 'participants', 'prepare', 'remarks']\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing pipeline\n",
    "\n",
    "# Function to check if a token is allowed in the preprocessing\n",
    "def is_token_allowed(token):\n",
    "    return bool(\n",
    "        token                   # Ensure token is not None\n",
    "        and str(token).strip()  # Ensure it's not empty\n",
    "        and not token.is_stop   # Not a stop word\n",
    "        and not token.is_punct  # Not a punctuation mark\n",
    "    )\n",
    "\n",
    "# Convert token to its lemma, stripped and lowercased\n",
    "def preprocess_token(token):\n",
    "    return token.lemma_.strip().lower()\n",
    "\n",
    "complete_filtered_tokens = [\n",
    "    preprocess_token(token)\n",
    "    for token in nvidia_doc\n",
    "    if is_token_allowed(token)\n",
    "]\n",
    "\n",
    "print(complete_filtered_tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69816145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted phone number: ['(123) 456-7890', '(212) 345-6789']\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Create matcher once\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add pattern once (outside function)\n",
    "phone_pattern = [\n",
    "    {\"ORTH\": \"(\"},\n",
    "    {\"SHAPE\": \"ddd\"},\n",
    "    {\"ORTH\": \")\"},\n",
    "    {\"SHAPE\": \"ddd\"},\n",
    "    {\"ORTH\": \"-\", \"OP\": \"?\"},   # match one or zero hyphen\n",
    "    {\"SHAPE\": \"dddd\"}\n",
    "]\n",
    "matcher.add(\"PHONE_NUMBER\", [phone_pattern])\n",
    "\n",
    "# Function just uses the matcher\n",
    "def extract_phone_number(nlp_doc):\n",
    "    phone_numbers = []\n",
    "    matches = matcher(nlp_doc)  # find all matches, returning a list of tuples [(match_id, start, end), ...]\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        phone_numbers.append(span.text)\n",
    "    return phone_numbers if phone_numbers else None\n",
    "\n",
    "# Use it\n",
    "extracted_number = extract_phone_number(nlp(\"Call me at (123) 456-7890 or (212) 345-6789 tomorrow.\"))\n",
    "print(f\"Extracted phone number: {extracted_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df2adddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          TOKEN: Apple\n",
      "          token.tag_ = 'NNP'\n",
      "          token.head.text = 'looking'\n",
      "          token.dep_ = 'nsubj'\n",
      "          \n",
      "\n",
      "          TOKEN: is\n",
      "          token.tag_ = 'VBZ'\n",
      "          token.head.text = 'looking'\n",
      "          token.dep_ = 'aux'\n",
      "          \n",
      "\n",
      "          TOKEN: looking\n",
      "          token.tag_ = 'VBG'\n",
      "          token.head.text = 'looking'\n",
      "          token.dep_ = 'ROOT'\n",
      "          \n",
      "\n",
      "          TOKEN: at\n",
      "          token.tag_ = 'IN'\n",
      "          token.head.text = 'looking'\n",
      "          token.dep_ = 'prep'\n",
      "          \n",
      "\n",
      "          TOKEN: buying\n",
      "          token.tag_ = 'VBG'\n",
      "          token.head.text = 'at'\n",
      "          token.dep_ = 'pcomp'\n",
      "          \n",
      "\n",
      "          TOKEN: U.K.\n",
      "          token.tag_ = 'NNP'\n",
      "          token.head.text = 'startup'\n",
      "          token.dep_ = 'nsubj'\n",
      "          \n",
      "\n",
      "          TOKEN: startup\n",
      "          token.tag_ = 'VBD'\n",
      "          token.head.text = 'buying'\n",
      "          token.dep_ = 'ccomp'\n",
      "          \n",
      "\n",
      "          TOKEN: for\n",
      "          token.tag_ = 'IN'\n",
      "          token.head.text = 'startup'\n",
      "          token.dep_ = 'prep'\n",
      "          \n",
      "\n",
      "          TOKEN: $\n",
      "          token.tag_ = '$'\n",
      "          token.head.text = 'billion'\n",
      "          token.dep_ = 'quantmod'\n",
      "          \n",
      "\n",
      "          TOKEN: 1\n",
      "          token.tag_ = 'CD'\n",
      "          token.head.text = 'billion'\n",
      "          token.dep_ = 'compound'\n",
      "          \n",
      "\n",
      "          TOKEN: billion\n",
      "          token.tag_ = 'CD'\n",
      "          token.head.text = 'for'\n",
      "          token.dep_ = 'pobj'\n",
      "          \n",
      "\n",
      "          TOKEN: .\n",
      "          token.tag_ = '.'\n",
      "          token.head.text = 'looking'\n",
      "          token.dep_ = 'punct'\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "small_test = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "small_doc = nlp(small_test)\n",
    "for token in small_doc:\n",
    "    print(f\"\"\"\n",
    "          TOKEN: {token.text}\n",
    "          {token.tag_ = }\n",
    "          {token.head.text = }\n",
    "          {token.dep_ = }\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c04039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a9a85c3448c24de1b99a997049eaf179-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,266.5 L1273.0,254.5 1257.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9a85c3448c24de1b99a997049eaf179-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9a85c3448c24de1b99a997049eaf179-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "html = displacy.render(small_doc, style=\"dep\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81a4fc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple', 'is', 'at', '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in small_doc[2].children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c733ec93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_doc[2].nbor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ff010b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "U.K.\n"
     ]
    }
   ],
   "source": [
    "for chunk in small_doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e4f6384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is looking\n"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "\n",
    "patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "small_doc2 = textacy.make_spacy_doc(small_test, lang=nlp)\n",
    "verb_phrases = textacy.extract.token_matches(\n",
    "    small_doc2, patterns=patterns\n",
    ")\n",
    "for chunk in verb_phrases:\n",
    "    print(chunk.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a3dc1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = displacy.render(small_doc, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26805270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of five people interviewed, three — [REDACTED] [REDACTED] , [REDACTED] [REDACTED] , and [REDACTED] [REDACTED] — were satisfied with the service.\n"
     ]
    }
   ],
   "source": [
    "# Redact person names\n",
    "survey_text = (\n",
    "    \"Out of five people interviewed, \"\n",
    "    \"three — John Parkinson, Jane Smith, \"\n",
    "    \"and Bob Johnson — were satisfied with the service.\"\n",
    ")\n",
    "\n",
    "def replace_person_names(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED] \"\n",
    "    return token.text_with_ws\n",
    "\n",
    "def redact_names(nlp_doc):\n",
    "    with nlp_doc.retokenize() as retokenizer:\n",
    "        for ent in nlp_doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "        tokens = map(replace_person_names, nlp_doc)\n",
    "        return \"\".join(tokens)\n",
    "    \n",
    "survey_doc = nlp(survey_text)\n",
    "print(redact_names(survey_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50e053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "xnwykphb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of five people interviewed, three - John Doe, [REDACTED][REDACTED], and [REDACTED][REDACTED]- were satisfied with the service.\n"
     ]
    }
   ],
   "source": [
    "# Redact person names\n",
    "survey_text = (\n",
    "    \"Out of five people interviewed, \"\n",
    "    \"three - John Doe, Jane Smith, \"\n",
    "    \"and Bob Johnson - were satisfied with the service.\"\n",
    ")\n",
    "\n",
    "def replace_person_names(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED]\"\n",
    "    return token.text_with_ws\n",
    "\n",
    "def redact_names(nlp_doc):\n",
    "    with nlp_doc.retokenize() as retokenizer:\n",
    "        for ent in nlp_doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "        tokens = map(replace_person_names, nlp_doc)\n",
    "        return \"\".join(tokens)\n",
    "    \n",
    "survey_doc = nlp(survey_text)\n",
    "print(redact_names(survey_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6w71hl75czu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (learning_python)",
   "language": "python",
   "name": "learning_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
