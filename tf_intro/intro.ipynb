{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac35263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c53b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f189098e2d143d98502678a93c4e73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9632867289564ae396196b1c9eed9dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefb3b90f12c4ee2a42032b58ed8f2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34acd2b98b474945ab4171099ce40186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eeb350370cd40c2aca10eb65dedcbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315469d55d0a4f8ab6b0d91574079c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_classifier = pipeline(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0961ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis result: [{'label': 'neutral', 'score': 0.403109073638916}]\n"
     ]
    }
   ],
   "source": [
    "text_input = \"Oh, great, another large language model. Whatever!\"\n",
    "result = sentiment_classifier(text_input)\n",
    "print(f\"Sentiment analysis result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a4c64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.403109073638916},\n",
       " {'label': 'positive', 'score': 0.5920102596282959},\n",
       " {'label': 'negative', 'score': 0.7665253281593323}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\"Oh, great, another large language model. Whatever!\",\n",
    "             \"I think this new AI agent is really different!\",\n",
    "             \"The weather is gloomy today.\"]\n",
    "sentiment_classifier(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88d6e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1058766b57e34bbd8217948b5a5184d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699e138bad1b406ea22b476f8c573e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/870M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003d6de7bf3e440c87e425604f0ae3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67050558a7f14c3fb46ae07900b8ab66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2007292ebbc24d9b9563732e15172e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8dc5fe39814382b77011946d384139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16372e1139d648b4ac656c6519038ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/970 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Zero-short text classification\n",
    "model_name = \"Moritzlaurer/deberta-v3-large-zeroshot-v2.0\"\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "candidate_labels = [\n",
    "    \"Billing Issues\",\n",
    "    \"Technical Support\",\n",
    "    \"Account Management\",\n",
    "    \"General Inquiry\"\n",
    "]\n",
    "hypothesis_template = \"This text is about {}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51d0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot classification result: {'sequence': 'I need help with my account password reset.', 'labels': ['Account Management', 'Technical Support', 'General Inquiry', 'Billing Issues'], 'scores': [0.8764230012893677, 0.7772998809814453, 0.04189131036400795, 6.0850405134260654e-05]}\n"
     ]
    }
   ],
   "source": [
    "customer_text = \"I need help with my account password reset.\"\n",
    "zero_shot_result = zero_shot_classifier(\n",
    "    customer_text,\n",
    "    candidate_labels=candidate_labels,\n",
    "    hypothesis_template=hypothesis_template,\n",
    "    multi_label=True\n",
    ")\n",
    "print(f\"Zero-shot classification result: {zero_shot_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba0b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9183e257ed924ef990f304c70ce05d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3675b453e9ee495aa413047e27a20fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247b865322d74fda92f4e644b50e133b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Image classification\n",
    "image_classifier = pipeline(\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650c8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'llama', 'score': 0.9988725781440735},\n",
       "  {'label': 'Arabian camel, dromedary, Camelus dromedarius',\n",
       "   'score': 9.834463708102703e-05},\n",
       "  {'label': 'standard poodle', 'score': 4.391697439132258e-05},\n",
       "  {'label': 'komondor', 'score': 3.7168701965129e-05},\n",
       "  {'label': 'ram, tup', 'score': 2.7737502023228444e-05}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = image_classifier([\"llamas.png\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5bcb621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dbd7681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'llama', 'score': 0.9988725781440735}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfab04b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: {'input_ids': tensor([[    0,  7516,     6,   372,     6,   277,   739,  2777,  1421,     4,\n",
      "         11999,   328,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "input_text = \"Oh, great, another large language model. Whatever!\"\n",
    "encoded_input = tokenizer(input_text, return_tensors='pt')\n",
    "print(f\"Encoded input: {encoded_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce71c542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  7516,     6,   372,     6,   277,   739,  2777,  1421,     4,\n",
       "         11999,   328,     2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad8dbac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Oh',\n",
       " ',',\n",
       " 'Ġgreat',\n",
       " ',',\n",
       " 'Ġanother',\n",
       " 'Ġlarge',\n",
       " 'Ġlanguage',\n",
       " 'Ġmodel',\n",
       " '.',\n",
       " 'ĠWhatever',\n",
       " '!',\n",
       " '</s>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a23613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f969337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = [\n",
    "    \"whaleshark\",\n",
    "    \"unicorn\",\n",
    "]\n",
    "tokenizer.convert_tokens_to_ids(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10cac0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee26d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "480dfd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50266"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"unicorn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1d28e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6238ae2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaEmbeddings(\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (token_type_embeddings): Embedding(1, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7367741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(input_text, return_tensors='pt')\n",
    "embedding_tensor = model.roberta.embeddings(encoded_input['input_ids'])\n",
    "embedding_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c541e8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0633, -0.0212,  0.0193,  ..., -0.0826, -0.0200, -0.0056],\n",
       "         [ 0.0370,  0.1577,  0.6688,  ...,  0.0043,  0.1001,  0.2352],\n",
       "         [ 0.3759,  0.0371, -0.3074,  ..., -0.6424, -0.3238,  0.0250],\n",
       "         ...,\n",
       "         [-0.3029,  0.1397,  0.2162,  ..., -0.0407,  0.1227, -0.4810],\n",
       "         [ 0.0392, -0.1928,  0.0224,  ..., -0.3784, -0.0536, -0.1739],\n",
       "         [ 0.1311, -0.0046, -0.1436,  ...,  0.2181, -0.0031, -0.2218]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04daa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"dtype\": \"float32\",\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"negative\",\n",
       "    \"1\": \"neutral\",\n",
       "    \"2\": \"positive\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"negative\": 0,\n",
       "    \"neutral\": 1,\n",
       "    \"positive\": 2\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "# config includes configuration details and metadata about the model\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101a557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3056, 0.4031, 0.2913])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Context manager, disable gradient calculation (used in inference to save memory and computations)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input) # \"**\"\" is used to unpack the dictionary into keyword arguments\n",
    "    \n",
    "scores = outputs.logits[0]\n",
    "probabilities = torch.softmax(scores, dim=0)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc03cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative: 0.3056\n",
      "neutral: 0.4031\n",
      "positive: 0.2913\n"
     ]
    }
   ],
   "source": [
    "for i, probability in enumerate(probabilities):\n",
    "    label = config.id2label[i]\n",
    "    print(f\"{label}: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f1bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
